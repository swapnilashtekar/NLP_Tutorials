{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "\n",
    "   \n",
    "    #Let's remove HTML tags using beautifulsoup4\n",
    "    # Initialize the BeautifulSoup object on a single movie review     \n",
    "    example1 = BeautifulSoup(train[\"review\"][0])  \n",
    "\n",
    "    # Print the raw review and then the output of get_text(), for \n",
    "    # comparison\n",
    "    #print train[\"review\"][0]\n",
    "    \n",
    "    #print example1.get_text()\n",
    "\n",
    "    #Let's remove the punctuations, numbers and stop words\n",
    "    # Use regular expressions to do a find-and-replace\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "    #print letters_only\n",
    "\n",
    "    #Tokenization\n",
    "    # Convert to lower case\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    # Split into words\n",
    "    words = lower_case.split()               \n",
    "    \n",
    "    #nltk.download()\n",
    "    #print \"Stop words are : \",stopwords.words(\"english\") \n",
    "\n",
    "    # Remove stop words from \"words\"\n",
    "    words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    \n",
    "    return( \" \".join( words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "train.head()\n",
    "train.shape, train.columns.values\n",
    "\n",
    "print train['review'][0]\n",
    "\n",
    "\n",
    "clean_review = review_to_words( train[\"review\"][0] )\n",
    "print \"-------------------------------------------------------------------------------------------------------------------\"\n",
    "print clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
    "clean_train_reviews = []\n",
    "num_reviews = train['review'].size\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating Bag of Words using Scikit-learn\n",
    "\n",
    "print \"Creating the bag of words...\\n\"\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "\"\"\"\n",
    "  fit_transform() does two functions: \n",
    "  First, it fits the model and learns the vocabulary; \n",
    "  second, it transforms our training data into feature vectors. \n",
    "  The input to fit_transform should be a list of strings.\n",
    "\"\"\"\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 166)\n"
     ]
    }
   ],
   "source": [
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'actual', u'alone', u'also', u'another', u'anyway', u'attention', u'away', u'bad', u'behind', u'bestest', u'beyond', u'biography', u'bit', u'boring', u'bottom', u'buddy', u'bunch', u'call', u'came', u'car', u'certain', u'character', u'cinema', u'closed', u'complex', u'consenting', u'convincing', u'cool', u'course', u'criminal', u'dance', u'dead', u'demon', u'different', u'director', u'directors', u'documentary', u'doors', u'drug', u'drugs', u'dunno', u'egotist', u'eighties', u'either', u'etc', u'ever', u'excluding', u'extremely', u'fact', u'fans', u'feature', u'feeling', u'film', u'filming', u'finally', u'find', u'gave', u'get', u'girl', u'give', u'going', u'grace', u'guilty', u'guy', u'hate', u'hates', u'hmmm', u'hope', u'impressive', u'innocent', u'insight', u'ironically', u'jackson', u'joe', u'kay', u'kid', u'kiddy', u'know', u'latter', u'let', u'level', u'liars', u'like', u'line', u'listening', u'lord', u'lots', u'made', u'make', u'making', u'may', u'maybe', u'message', u'messages', u'michael', u'mind', u'minutes', u'mj', u'moment', u'moonwalker', u'movie', u'music', u'must', u'nah', u'nice', u'obvious', u'odd', u'one', u'originally', u'overheard', u'part', u'patience', u'people', u'performing', u'pesci', u'planet', u'plans', u'powerful', u'press', u'psychopathic', u'ranted', u'really', u'released', u'remember', u'remotely', u'robot', u'saint', u'say', u'scene', u'see', u'sequence', u'sickest', u'smooth', u'speed', u'started', u'starts', u'stay', u'stuff', u'stupid', u'subject', u'subtle', u'supplying', u'talented', u'things', u'think', u'thought', u'towards', u'true', u'truly', u'try', u'turning', u'unless', u'usually', u'visually', u'want', u'wanted', u'wants', u'watched', u'watching', u'well', u'whether', u'whole', u'wholesome', u'wiz', u'working', u'would']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 actual\n",
      "25000 alone\n",
      "50000 also\n",
      "25000 another\n",
      "25000 anyway\n",
      "25000 attention\n",
      "25000 away\n",
      "75000 bad\n",
      "25000 behind\n",
      "25000 bestest\n",
      "25000 beyond\n",
      "25000 biography\n",
      "25000 bit\n",
      "25000 boring\n",
      "25000 bottom\n",
      "25000 buddy\n",
      "25000 bunch\n",
      "25000 call\n",
      "25000 came\n",
      "25000 car\n",
      "25000 certain\n",
      "25000 character\n",
      "25000 cinema\n",
      "25000 closed\n",
      "25000 complex\n",
      "25000 consenting\n",
      "25000 convincing\n",
      "50000 cool\n",
      "25000 course\n",
      "25000 criminal\n",
      "25000 dance\n",
      "25000 dead\n",
      "25000 demon\n",
      "25000 different\n",
      "25000 director\n",
      "25000 directors\n",
      "25000 documentary\n",
      "25000 doors\n",
      "25000 drug\n",
      "50000 drugs\n",
      "25000 dunno\n",
      "25000 egotist\n",
      "25000 eighties\n",
      "25000 either\n",
      "25000 etc\n",
      "25000 ever\n",
      "25000 excluding\n",
      "25000 extremely\n",
      "25000 fact\n",
      "50000 fans\n",
      "50000 feature\n",
      "25000 feeling\n",
      "50000 film\n",
      "25000 filming\n",
      "25000 finally\n",
      "25000 find\n",
      "25000 gave\n",
      "25000 get\n",
      "25000 girl\n",
      "25000 give\n",
      "75000 going\n",
      "25000 grace\n",
      "50000 guilty\n",
      "50000 guy\n",
      "50000 hate\n",
      "25000 hates\n",
      "25000 hmmm\n",
      "25000 hope\n",
      "25000 impressive\n",
      "25000 innocent\n",
      "25000 insight\n",
      "25000 ironically\n",
      "50000 jackson\n",
      "50000 joe\n",
      "25000 kay\n",
      "25000 kid\n",
      "25000 kiddy\n",
      "75000 know\n",
      "25000 latter\n",
      "25000 let\n",
      "25000 level\n",
      "25000 liars\n",
      "75000 like\n",
      "25000 line\n",
      "25000 listening\n",
      "25000 lord\n",
      "25000 lots\n",
      "25000 made\n",
      "25000 make\n",
      "25000 making\n",
      "25000 may\n",
      "75000 maybe\n",
      "50000 message\n",
      "25000 messages\n",
      "50000 michael\n",
      "25000 mind\n",
      "25000 minutes\n",
      "275000 mj\n",
      "25000 moment\n",
      "50000 moonwalker\n",
      "75000 movie\n",
      "50000 music\n",
      "25000 must\n",
      "25000 nah\n",
      "50000 nice\n",
      "25000 obvious\n",
      "25000 odd\n",
      "100000 one\n",
      "25000 originally\n",
      "25000 overheard\n",
      "50000 part\n",
      "25000 patience\n",
      "125000 people\n",
      "25000 performing\n",
      "50000 pesci\n",
      "25000 planet\n",
      "25000 plans\n",
      "25000 powerful\n",
      "25000 press\n",
      "25000 psychopathic\n",
      "25000 ranted\n",
      "50000 really\n",
      "25000 released\n",
      "25000 remember\n",
      "25000 remotely\n",
      "25000 robot\n",
      "25000 saint\n",
      "25000 say\n",
      "25000 scene\n",
      "25000 see\n",
      "75000 sequence\n",
      "25000 sickest\n",
      "25000 smooth\n",
      "25000 speed\n",
      "25000 started\n",
      "25000 starts\n",
      "25000 stay\n",
      "25000 stuff\n",
      "25000 stupid\n",
      "25000 subject\n",
      "25000 subtle\n",
      "25000 supplying\n",
      "25000 talented\n",
      "25000 things\n",
      "25000 think\n",
      "25000 thought\n",
      "25000 towards\n",
      "25000 true\n",
      "25000 truly\n",
      "25000 try\n",
      "25000 turning\n",
      "25000 unless\n",
      "25000 usually\n",
      "25000 visually\n",
      "25000 want\n",
      "25000 wanted\n",
      "25000 wants\n",
      "50000 watched\n",
      "25000 watching\n",
      "50000 well\n",
      "25000 whether\n",
      "50000 whole\n",
      "25000 wholesome\n",
      "25000 wiz\n",
      "25000 working\n",
      "25000 would\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "\"\"\"\n",
    "    Fit the forest to the training set, using the bag of words as features and the sentiment \n",
    "    labels as the response variable\n",
    "    This may take a few minutes to run\n",
    "\"\"\"\n",
    "\n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
